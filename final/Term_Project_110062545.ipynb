{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/04 21:43:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "import hashlib\n",
    "import re\n",
    "\n",
    "conf = pyspark.SparkConf().setMaster('local').setAppName('lsh')\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "## readData\n",
    "用 `wholeTextFiles` 把所有檔案讀入，再將每個txt檔的內容，一個字一個字檢查是不是含有特殊符號，因為題目要求3-shingles，所以把三個字concat在一起，為了節省空間，我使用`hashlib.sha256`轉成32bits，最後把資料存成`(file_id, [shingle1, shingle2,...])`，接著將資料轉成類似矩陣的結構`[(shingle1, [file_id]), (shingle2, [file_id])]`，最後的資料結構是`[(1, [file_id1, file_id2]), (2, [file_id2, file_id3]),...]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(x):\n",
    "    file_id = int(x[0][-7:-4])\n",
    "    content = x[1]\n",
    "    res = []\n",
    "    for l in content.splitlines():\n",
    "\n",
    "        words = l.split(' ')\n",
    "        new_words = []\n",
    "        for i in words:\n",
    "            i = re.sub('[^a-zA-Z0-9]$', '', i)\n",
    "            i = re.sub('^[^a-zA-Z0-9]', '', i)\n",
    "            new_words.append(i)\n",
    "        for i in range(len(new_words)-2):\n",
    "            shingles = new_words[i] + new_words[i+1] + new_words[i+2]\n",
    "            shingles = int.from_bytes(hashlib.sha256(shingles.encode('utf8')).digest()[:4], 'little')\n",
    "            res.append(shingles)\n",
    "\n",
    "    return (file_id, res)\n",
    "\n",
    "\n",
    "original_data = sc.wholeTextFiles('./athletics/*.txt').map(readData)\n",
    "hash_matrix = original_data.flatMapValues(lambda x: x).map(lambda x: (x[1], [x[0]])).reduceByKey(lambda x, y: x+y).sortBy(lambda x: x[0], ascending=True)\n",
    "hash_matrix = hash_matrix.zipWithIndex().map(lambda x: (x[1], x[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min_hash\n",
    "這裡實作題目所要求產生100個hash function，並且將資料轉成`[((row, file_id, hash_function_id), hash_value)]`，最後的lambda function 更新最小的hash value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def min_hash(x):\n",
    "    l = []\n",
    "    res = []\n",
    "    for i in range(100):\n",
    "        hash_func = i * x[0] % 22111 % keys_conut\n",
    "        l.append(hash_func)\n",
    "    for i in x[1]:\n",
    "        for idx, val in enumerate(l):\n",
    "            res.append(((x[0], i, idx), val))\n",
    "    return res\n",
    "    \n",
    "keys_conut = hash_matrix.keys().count()\n",
    "signature_matrix = hash_matrix.flatMap(min_hash).reduceByKey(lambda x, y: x if x < y else y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gen_candidate_pair\n",
    "這裡實作相同bucket的文章找出類似的文章\n",
    "\n",
    "## cal_sim\n",
    "計算Jaccard Similarity，找出union跟intersection的數量\n",
    "\n",
    "## hash_bucket\n",
    "因為題目要求50個band，所以將原本100個hash function直接除二，當作band的id，最後再把資料做hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_candidate_pair(x):\n",
    "    res = []\n",
    "    for i in x[1]:\n",
    "        for j in x[1]:\n",
    "            if i != j:\n",
    "                if i < j:\n",
    "                    res.append((i, j))\n",
    "                else:\n",
    "                    res.append((j, i))\n",
    "    return list(set(res))\n",
    "\n",
    "def cal_sim(x):\n",
    "    union = set(x[1][0]).union(set(x[1][1]))\n",
    "    inter = set(x[1][0]).intersection(set(x[1][1]))\n",
    "    \n",
    "    return (x[0], len(inter) / len(union))\n",
    "\n",
    "\n",
    "def hash_bucket(x):\n",
    "    if x[0][0] % 2 == 0:\n",
    "        return ((x[0][0] // 2, x[0][1]), x[1])\n",
    "    else:\n",
    "        return ((x[0][0] // 2, x[0][1]), x[1] * keys_conut)\n",
    "\n",
    "lsh_matrix = signature_matrix.map(hash_bucket).reduceByKey(lambda x, y: x + y)\n",
    "lsh_matrix = lsh_matrix.map(lambda x: ((x[0][0], x[1]), [x[0][1]])).reduceByKey(lambda x, y: x + y)\n",
    "candidate_pairs = lsh_matrix.flatMap(gen_candidate_pair).distinct()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Result\n",
    "這裡將candidate pairs 與原本的資料join，並將結果的key改到後面，再做一次join把結果排列成`((file_id1, file_id2), ([shingle1, shingle2], [shingle2]))`，最後算出相似度後用降冪排列就得到答案了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(052, 084): 100.00 %\n",
      "(012, 020): 100.00 %\n",
      "(047, 049): 75.74 %\n",
      "(030, 035): 71.00 %\n",
      "(049, 088): 51.47 %\n",
      "(048, 049): 48.58 %\n",
      "(023, 038): 48.18 %\n",
      "(014, 040): 39.97 %\n",
      "(047, 088): 39.02 %\n",
      "(047, 048): 36.79 %\n"
     ]
    }
   ],
   "source": [
    "sim_pairs = candidate_pairs.join(original_data).map(lambda x: (x[1][0], (x[0], x[1][1]))).join(\n",
    "    original_data).map(lambda x: ((x[1][0][0], x[0]), (x[1][0][1], x[1][1])))\n",
    "sim_pairs = sim_pairs.map(cal_sim).sortBy(lambda x: x[1], ascending=False)\n",
    "\n",
    "ans = sim_pairs.take(10)\n",
    "for i in ans:\n",
    "    print('(%03d, %03d): %.2f %s' % (i[0][0], i[0][1], i[1]*100, '%'))\n",
    "\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}